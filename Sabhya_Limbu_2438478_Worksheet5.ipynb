{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Step -1- Data Understanding, Analysis and Preparations:\n",
        "\n",
        "• To - Do - 1:\n",
        "\n",
        "1. Read and Observe the Dataset."
      ],
      "metadata": {
        "id": "j7UmL1duMBSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/drive/MyDrive/Concept and technologies of AI/student.csv')"
      ],
      "metadata": {
        "id": "bGr0apMvMLzS"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKMLVZdU-HCz",
        "outputId": "1c83f972-a1b1-4284-f81c-c000ad41c9b4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Print top(5) and bottom(5) of the dataset {Hint: pd.head and pd.tail}."
      ],
      "metadata": {
        "id": "cfC7MI5MNJwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(5)"
      ],
      "metadata": {
        "id": "LJ4J5zvXNNtz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "5c80ec0d-d9a5-439e-c8a8-32597774d9dd"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Math  Reading  Writing\n",
              "0    48       68       63\n",
              "1    62       81       72\n",
              "2    79       80       78\n",
              "3    76       83       79\n",
              "4    59       64       62"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e400c36-5266-493a-a0de-47b06447d2af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Math</th>\n",
              "      <th>Reading</th>\n",
              "      <th>Writing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>48</td>\n",
              "      <td>68</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>62</td>\n",
              "      <td>81</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>79</td>\n",
              "      <td>80</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>76</td>\n",
              "      <td>83</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59</td>\n",
              "      <td>64</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e400c36-5266-493a-a0de-47b06447d2af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8e400c36-5266-493a-a0de-47b06447d2af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8e400c36-5266-493a-a0de-47b06447d2af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ed628387-070a-4ee6-b86f-f595dd7b5436\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ed628387-070a-4ee6-b86f-f595dd7b5436')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ed628387-070a-4ee6-b86f-f595dd7b5436 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"Math\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 13,\n        \"max\": 100,\n        \"num_unique_values\": 75,\n        \"samples\": [\n          59,\n          34,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reading\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 19,\n        \"max\": 100,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          64,\n          45,\n          52\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Writing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 14,\n        \"max\": 100,\n        \"num_unique_values\": 76,\n        \"samples\": [\n          62,\n          91,\n          64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail(5)"
      ],
      "metadata": {
        "id": "tnI27-fNNaWu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8c96a978-bd1a-40ae-f97a-3348f1114288"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Math  Reading  Writing\n",
              "995    72       74       70\n",
              "996    73       86       90\n",
              "997    89       87       94\n",
              "998    83       82       78\n",
              "999    66       66       72"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be5ced1c-4b43-421a-ab42-5c51655d6862\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Math</th>\n",
              "      <th>Reading</th>\n",
              "      <th>Writing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>72</td>\n",
              "      <td>74</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>73</td>\n",
              "      <td>86</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>89</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>83</td>\n",
              "      <td>82</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>66</td>\n",
              "      <td>66</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be5ced1c-4b43-421a-ab42-5c51655d6862')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-be5ced1c-4b43-421a-ab42-5c51655d6862 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-be5ced1c-4b43-421a-ab42-5c51655d6862');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6a92b35b-c665-4fed-94b6-ab6761ab29d4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a92b35b-c665-4fed-94b6-ab6761ab29d4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6a92b35b-c665-4fed-94b6-ab6761ab29d4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Math\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 66,\n        \"max\": 89,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          73,\n          66,\n          89\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reading\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 66,\n        \"max\": 87,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          86,\n          66,\n          87\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Writing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 70,\n        \"max\": 94,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          90,\n          72,\n          94\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Print the Information of Datasets. {Hint: pd.info}."
      ],
      "metadata": {
        "id": "yyt_DfNHNeIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "DmUfH6M4NhKG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46390cf5-0b1f-4c3b-cfa1-8d9f983ecf02"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype\n",
            "---  ------   --------------  -----\n",
            " 0   Math     1000 non-null   int64\n",
            " 1   Reading  1000 non-null   int64\n",
            " 2   Writing  1000 non-null   int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 23.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Gather the Descriptive info about the Dataset. {Hint: pd.describe}"
      ],
      "metadata": {
        "id": "ISv1J-QtN0Hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "8g7bkOmXN04P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "6ce0be4e-dad4-4fbc-f3b3-ed9a81503497"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Math      Reading      Writing\n",
              "count  1000.000000  1000.000000  1000.000000\n",
              "mean     67.290000    69.872000    68.616000\n",
              "std      15.085008    14.657027    15.241287\n",
              "min      13.000000    19.000000    14.000000\n",
              "25%      58.000000    60.750000    58.000000\n",
              "50%      68.000000    70.000000    69.500000\n",
              "75%      78.000000    81.000000    79.000000\n",
              "max     100.000000   100.000000   100.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b3b278a-9aa1-4cbf-a6b5-e769c945de1b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Math</th>\n",
              "      <th>Reading</th>\n",
              "      <th>Writing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>67.290000</td>\n",
              "      <td>69.872000</td>\n",
              "      <td>68.616000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>15.085008</td>\n",
              "      <td>14.657027</td>\n",
              "      <td>15.241287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>13.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>58.000000</td>\n",
              "      <td>60.750000</td>\n",
              "      <td>58.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>68.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>69.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>78.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>79.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b3b278a-9aa1-4cbf-a6b5-e769c945de1b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5b3b278a-9aa1-4cbf-a6b5-e769c945de1b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5b3b278a-9aa1-4cbf-a6b5-e769c945de1b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-70f46a15-a795-4d91-acd4-20d3a707b43c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-70f46a15-a795-4d91-acd4-20d3a707b43c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-70f46a15-a795-4d91-acd4-20d3a707b43c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Math\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 334.70993839737343,\n        \"min\": 13.0,\n        \"max\": 1000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          67.29,\n          68.0,\n          1000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reading\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 333.8589622553041,\n        \"min\": 14.65702713528377,\n        \"max\": 1000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          69.872,\n          70.0,\n          1000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Writing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 334.45996524707175,\n        \"min\": 14.0,\n        \"max\": 1000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          68.616,\n          69.5,\n          1000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Split your data into Feature (X) and Label (Y)."
      ],
      "metadata": {
        "id": "R2XNgRTiN5Xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[['Math', 'Reading']]\n",
        "Y = data['Writing']"
      ],
      "metadata": {
        "id": "ViQzOm7uN_QE"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To - Do - 2:\n",
        "1. To make the task easier - let’s assume there is no bias or intercept.\n",
        "2. Create the following matrices:"
      ],
      "metadata": {
        "id": "N2z68UGMOVEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "cC0g36-JOXwo"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Concept and technologies of AI/student.csv')\n",
        "X = data[['Math', 'Reading']].values\n",
        "Y = data['Writing'].values\n",
        "\n",
        "# Step 2: Initialize W (weight vector) randomly\n",
        "W = np.random.randn(X.shape[1], 1)\n",
        "\n",
        "# Step 3: Convert X into the required matrix form\n",
        "X = X.T\n",
        "\n",
        "# Step 4: Convert Y into the required matrix form (shape (n, 1))\n",
        "Y = Y.reshape(-1, 1)  # Convert Y to shape (n, 1)\n",
        "\n",
        "# Display the matrices\n",
        "print(\"Matrix X (Feature matrix):\")\n",
        "print(X)\n",
        "\n",
        "print(\"\\nMatrix W (Weight vector):\")\n",
        "print(W)\n",
        "\n",
        "print(\"\\nMatrix Y (Target vector):\")\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "1GqudDluObBv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c982396-b239-435c-f0e9-dfa101a8e2de"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix X (Feature matrix):\n",
            "[[48 62 79 ... 89 83 66]\n",
            " [68 81 80 ... 87 82 66]]\n",
            "\n",
            "Matrix W (Weight vector):\n",
            "[[-1.95827161]\n",
            " [-0.51796269]]\n",
            "\n",
            "Matrix Y (Target vector):\n",
            "[[ 63]\n",
            " [ 72]\n",
            " [ 78]\n",
            " [ 79]\n",
            " [ 62]\n",
            " [ 85]\n",
            " [ 83]\n",
            " [ 41]\n",
            " [ 80]\n",
            " [ 77]\n",
            " [ 64]\n",
            " [ 90]\n",
            " [ 45]\n",
            " [ 77]\n",
            " [ 70]\n",
            " [ 46]\n",
            " [ 76]\n",
            " [ 44]\n",
            " [ 85]\n",
            " [ 72]\n",
            " [ 53]\n",
            " [ 66]\n",
            " [ 75]\n",
            " [ 49]\n",
            " [ 84]\n",
            " [ 83]\n",
            " [ 68]\n",
            " [ 66]\n",
            " [ 77]\n",
            " [ 78]\n",
            " [ 74]\n",
            " [ 83]\n",
            " [ 72]\n",
            " [ 65]\n",
            " [ 46]\n",
            " [ 66]\n",
            " [ 50]\n",
            " [ 79]\n",
            " [ 68]\n",
            " [ 46]\n",
            " [ 86]\n",
            " [ 70]\n",
            " [ 61]\n",
            " [ 53]\n",
            " [ 72]\n",
            " [ 75]\n",
            " [ 50]\n",
            " [ 77]\n",
            " [100]\n",
            " [ 81]\n",
            " [100]\n",
            " [ 87]\n",
            " [ 78]\n",
            " [ 48]\n",
            " [ 50]\n",
            " [ 44]\n",
            " [ 48]\n",
            " [ 43]\n",
            " [ 67]\n",
            " [ 78]\n",
            " [ 58]\n",
            " [ 91]\n",
            " [ 92]\n",
            " [ 78]\n",
            " [ 42]\n",
            " [ 85]\n",
            " [ 73]\n",
            " [ 83]\n",
            " [ 61]\n",
            " [ 58]\n",
            " [ 60]\n",
            " [ 55]\n",
            " [ 48]\n",
            " [ 62]\n",
            " [ 68]\n",
            " [ 59]\n",
            " [ 62]\n",
            " [ 48]\n",
            " [ 74]\n",
            " [ 63]\n",
            " [ 80]\n",
            " [ 79]\n",
            " [ 73]\n",
            " [ 79]\n",
            " [ 45]\n",
            " [ 67]\n",
            " [ 89]\n",
            " [ 77]\n",
            " [ 81]\n",
            " [ 88]\n",
            " [ 53]\n",
            " [ 68]\n",
            " [ 79]\n",
            " [ 77]\n",
            " [ 63]\n",
            " [ 73]\n",
            " [ 60]\n",
            " [ 67]\n",
            " [100]\n",
            " [ 79]\n",
            " [ 26]\n",
            " [ 51]\n",
            " [ 80]\n",
            " [ 57]\n",
            " [ 41]\n",
            " [ 78]\n",
            " [ 68]\n",
            " [ 49]\n",
            " [ 76]\n",
            " [ 41]\n",
            " [ 71]\n",
            " [ 77]\n",
            " [ 89]\n",
            " [ 86]\n",
            " [ 55]\n",
            " [ 80]\n",
            " [ 56]\n",
            " [ 74]\n",
            " [ 85]\n",
            " [ 80]\n",
            " [ 73]\n",
            " [ 74]\n",
            " [ 86]\n",
            " [ 56]\n",
            " [ 53]\n",
            " [ 44]\n",
            " [ 41]\n",
            " [ 59]\n",
            " [ 71]\n",
            " [ 81]\n",
            " [ 74]\n",
            " [ 78]\n",
            " [ 67]\n",
            " [ 53]\n",
            " [ 56]\n",
            " [ 75]\n",
            " [ 82]\n",
            " [ 79]\n",
            " [ 99]\n",
            " [ 76]\n",
            " [ 59]\n",
            " [ 96]\n",
            " [ 75]\n",
            " [ 61]\n",
            " [ 56]\n",
            " [ 88]\n",
            " [ 65]\n",
            " [100]\n",
            " [ 79]\n",
            " [ 55]\n",
            " [ 61]\n",
            " [ 83]\n",
            " [ 74]\n",
            " [ 59]\n",
            " [ 54]\n",
            " [ 47]\n",
            " [ 82]\n",
            " [ 74]\n",
            " [ 59]\n",
            " [ 74]\n",
            " [ 84]\n",
            " [ 59]\n",
            " [ 43]\n",
            " [ 65]\n",
            " [ 61]\n",
            " [ 78]\n",
            " [ 84]\n",
            " [ 73]\n",
            " [ 73]\n",
            " [ 92]\n",
            " [ 63]\n",
            " [ 72]\n",
            " [ 61]\n",
            " [ 59]\n",
            " [ 70]\n",
            " [ 87]\n",
            " [ 78]\n",
            " [ 65]\n",
            " [ 73]\n",
            " [ 62]\n",
            " [ 69]\n",
            " [ 55]\n",
            " [ 73]\n",
            " [ 63]\n",
            " [ 67]\n",
            " [ 86]\n",
            " [ 78]\n",
            " [ 85]\n",
            " [ 83]\n",
            " [ 80]\n",
            " [ 60]\n",
            " [ 90]\n",
            " [ 56]\n",
            " [ 70]\n",
            " [ 55]\n",
            " [ 80]\n",
            " [ 82]\n",
            " [ 60]\n",
            " [ 78]\n",
            " [ 76]\n",
            " [ 94]\n",
            " [ 75]\n",
            " [ 68]\n",
            " [ 71]\n",
            " [ 85]\n",
            " [ 46]\n",
            " [ 58]\n",
            " [ 46]\n",
            " [ 84]\n",
            " [ 58]\n",
            " [ 57]\n",
            " [ 59]\n",
            " [ 77]\n",
            " [ 63]\n",
            " [ 68]\n",
            " [ 99]\n",
            " [ 48]\n",
            " [ 91]\n",
            " [ 57]\n",
            " [ 80]\n",
            " [ 46]\n",
            " [ 75]\n",
            " [ 59]\n",
            " [ 87]\n",
            " [ 82]\n",
            " [ 79]\n",
            " [ 66]\n",
            " [ 68]\n",
            " [ 66]\n",
            " [ 61]\n",
            " [ 66]\n",
            " [ 63]\n",
            " [ 72]\n",
            " [ 73]\n",
            " [ 77]\n",
            " [ 84]\n",
            " [ 83]\n",
            " [ 42]\n",
            " [ 72]\n",
            " [ 76]\n",
            " [ 76]\n",
            " [ 39]\n",
            " [ 74]\n",
            " [ 43]\n",
            " [ 63]\n",
            " [ 74]\n",
            " [ 52]\n",
            " [ 31]\n",
            " [ 65]\n",
            " [ 45]\n",
            " [ 87]\n",
            " [ 63]\n",
            " [ 51]\n",
            " [ 82]\n",
            " [ 86]\n",
            " [ 76]\n",
            " [ 27]\n",
            " [ 70]\n",
            " [ 79]\n",
            " [ 66]\n",
            " [ 61]\n",
            " [ 62]\n",
            " [ 47]\n",
            " [ 17]\n",
            " [ 65]\n",
            " [ 76]\n",
            " [ 75]\n",
            " [ 66]\n",
            " [ 59]\n",
            " [ 61]\n",
            " [ 93]\n",
            " [ 40]\n",
            " [ 66]\n",
            " [ 43]\n",
            " [ 71]\n",
            " [ 64]\n",
            " [ 55]\n",
            " [ 86]\n",
            " [ 65]\n",
            " [ 70]\n",
            " [ 65]\n",
            " [ 53]\n",
            " [ 49]\n",
            " [ 67]\n",
            " [ 76]\n",
            " [ 95]\n",
            " [ 76]\n",
            " [ 48]\n",
            " [ 60]\n",
            " [ 53]\n",
            " [ 69]\n",
            " [ 78]\n",
            " [ 62]\n",
            " [ 66]\n",
            " [ 51]\n",
            " [ 52]\n",
            " [ 46]\n",
            " [ 42]\n",
            " [ 77]\n",
            " [ 57]\n",
            " [100]\n",
            " [ 84]\n",
            " [ 68]\n",
            " [ 48]\n",
            " [ 72]\n",
            " [ 50]\n",
            " [ 72]\n",
            " [ 55]\n",
            " [ 72]\n",
            " [ 77]\n",
            " [ 56]\n",
            " [ 94]\n",
            " [ 67]\n",
            " [ 82]\n",
            " [ 75]\n",
            " [ 80]\n",
            " [ 60]\n",
            " [ 73]\n",
            " [ 74]\n",
            " [ 62]\n",
            " [ 53]\n",
            " [ 69]\n",
            " [ 75]\n",
            " [ 60]\n",
            " [ 58]\n",
            " [ 71]\n",
            " [ 87]\n",
            " [ 74]\n",
            " [ 87]\n",
            " [ 73]\n",
            " [ 78]\n",
            " [ 76]\n",
            " [ 74]\n",
            " [ 55]\n",
            " [ 94]\n",
            " [ 71]\n",
            " [ 76]\n",
            " [ 59]\n",
            " [ 91]\n",
            " [ 57]\n",
            " [ 83]\n",
            " [ 59]\n",
            " [ 93]\n",
            " [ 64]\n",
            " [ 58]\n",
            " [ 79]\n",
            " [ 96]\n",
            " [ 76]\n",
            " [ 64]\n",
            " [ 70]\n",
            " [ 80]\n",
            " [ 33]\n",
            " [ 95]\n",
            " [ 64]\n",
            " [ 92]\n",
            " [ 34]\n",
            " [ 72]\n",
            " [ 81]\n",
            " [ 57]\n",
            " [ 79]\n",
            " [ 84]\n",
            " [ 82]\n",
            " [ 54]\n",
            " [ 45]\n",
            " [ 54]\n",
            " [ 62]\n",
            " [ 49]\n",
            " [ 74]\n",
            " [ 59]\n",
            " [ 63]\n",
            " [ 83]\n",
            " [ 62]\n",
            " [ 72]\n",
            " [ 72]\n",
            " [ 65]\n",
            " [ 65]\n",
            " [ 54]\n",
            " [ 78]\n",
            " [ 82]\n",
            " [ 85]\n",
            " [ 74]\n",
            " [ 83]\n",
            " [ 71]\n",
            " [ 83]\n",
            " [ 77]\n",
            " [ 66]\n",
            " [ 75]\n",
            " [ 52]\n",
            " [ 68]\n",
            " [ 84]\n",
            " [ 67]\n",
            " [ 70]\n",
            " [ 41]\n",
            " [ 91]\n",
            " [ 46]\n",
            " [ 58]\n",
            " [ 67]\n",
            " [ 70]\n",
            " [ 83]\n",
            " [ 64]\n",
            " [100]\n",
            " [ 49]\n",
            " [ 77]\n",
            " [ 57]\n",
            " [ 67]\n",
            " [ 80]\n",
            " [ 74]\n",
            " [ 41]\n",
            " [ 67]\n",
            " [ 59]\n",
            " [ 86]\n",
            " [ 88]\n",
            " [ 57]\n",
            " [ 80]\n",
            " [ 58]\n",
            " [ 52]\n",
            " [ 31]\n",
            " [ 84]\n",
            " [ 97]\n",
            " [ 71]\n",
            " [ 62]\n",
            " [ 58]\n",
            " [ 71]\n",
            " [ 41]\n",
            " [ 66]\n",
            " [100]\n",
            " [ 51]\n",
            " [ 35]\n",
            " [ 81]\n",
            " [ 94]\n",
            " [ 72]\n",
            " [ 38]\n",
            " [ 82]\n",
            " [ 79]\n",
            " [ 55]\n",
            " [ 75]\n",
            " [ 90]\n",
            " [ 95]\n",
            " [ 65]\n",
            " [ 39]\n",
            " [ 85]\n",
            " [ 86]\n",
            " [ 54]\n",
            " [ 93]\n",
            " [ 69]\n",
            " [ 84]\n",
            " [ 78]\n",
            " [ 58]\n",
            " [ 73]\n",
            " [ 60]\n",
            " [ 44]\n",
            " [ 67]\n",
            " [ 69]\n",
            " [ 55]\n",
            " [ 59]\n",
            " [ 88]\n",
            " [ 42]\n",
            " [ 78]\n",
            " [ 84]\n",
            " [ 68]\n",
            " [ 66]\n",
            " [ 51]\n",
            " [ 43]\n",
            " [ 38]\n",
            " [ 69]\n",
            " [ 90]\n",
            " [ 73]\n",
            " [ 67]\n",
            " [ 57]\n",
            " [ 81]\n",
            " [ 63]\n",
            " [ 80]\n",
            " [ 78]\n",
            " [ 65]\n",
            " [ 74]\n",
            " [ 80]\n",
            " [ 60]\n",
            " [ 60]\n",
            " [ 63]\n",
            " [ 64]\n",
            " [ 72]\n",
            " [ 51]\n",
            " [ 71]\n",
            " [ 63]\n",
            " [ 82]\n",
            " [ 76]\n",
            " [ 39]\n",
            " [ 79]\n",
            " [ 48]\n",
            " [ 70]\n",
            " [ 90]\n",
            " [ 73]\n",
            " [ 58]\n",
            " [100]\n",
            " [ 80]\n",
            " [ 75]\n",
            " [ 72]\n",
            " [ 79]\n",
            " [ 52]\n",
            " [ 56]\n",
            " [ 65]\n",
            " [ 45]\n",
            " [ 59]\n",
            " [ 61]\n",
            " [ 47]\n",
            " [ 62]\n",
            " [ 83]\n",
            " [ 90]\n",
            " [ 76]\n",
            " [ 72]\n",
            " [ 69]\n",
            " [ 57]\n",
            " [ 56]\n",
            " [ 40]\n",
            " [ 79]\n",
            " [ 48]\n",
            " [ 57]\n",
            " [ 47]\n",
            " [ 78]\n",
            " [ 45]\n",
            " [ 74]\n",
            " [ 69]\n",
            " [ 59]\n",
            " [ 85]\n",
            " [ 45]\n",
            " [ 54]\n",
            " [ 72]\n",
            " [ 74]\n",
            " [ 75]\n",
            " [ 55]\n",
            " [ 49]\n",
            " [ 53]\n",
            " [ 83]\n",
            " [ 22]\n",
            " [100]\n",
            " [ 67]\n",
            " [ 83]\n",
            " [ 46]\n",
            " [ 43]\n",
            " [ 74]\n",
            " [ 64]\n",
            " [ 35]\n",
            " [ 67]\n",
            " [ 87]\n",
            " [ 77]\n",
            " [ 91]\n",
            " [ 74]\n",
            " [ 96]\n",
            " [ 82]\n",
            " [ 78]\n",
            " [ 73]\n",
            " [ 52]\n",
            " [ 91]\n",
            " [ 66]\n",
            " [ 67]\n",
            " [ 71]\n",
            " [ 74]\n",
            " [ 71]\n",
            " [ 61]\n",
            " [ 47]\n",
            " [ 76]\n",
            " [ 85]\n",
            " [ 93]\n",
            " [ 41]\n",
            " [ 81]\n",
            " [ 86]\n",
            " [ 53]\n",
            " [ 91]\n",
            " [ 68]\n",
            " [ 96]\n",
            " [ 48]\n",
            " [ 71]\n",
            " [ 75]\n",
            " [ 72]\n",
            " [ 71]\n",
            " [ 62]\n",
            " [ 67]\n",
            " [ 53]\n",
            " [ 74]\n",
            " [ 63]\n",
            " [ 82]\n",
            " [ 57]\n",
            " [ 69]\n",
            " [ 52]\n",
            " [ 91]\n",
            " [ 73]\n",
            " [ 73]\n",
            " [ 75]\n",
            " [ 36]\n",
            " [ 71]\n",
            " [ 62]\n",
            " [100]\n",
            " [ 50]\n",
            " [ 74]\n",
            " [ 60]\n",
            " [ 75]\n",
            " [ 83]\n",
            " [ 83]\n",
            " [100]\n",
            " [ 67]\n",
            " [ 71]\n",
            " [ 77]\n",
            " [ 67]\n",
            " [ 95]\n",
            " [ 52]\n",
            " [ 71]\n",
            " [ 74]\n",
            " [ 60]\n",
            " [ 67]\n",
            " [ 79]\n",
            " [ 75]\n",
            " [ 95]\n",
            " [ 69]\n",
            " [ 80]\n",
            " [ 48]\n",
            " [ 61]\n",
            " [ 82]\n",
            " [ 39]\n",
            " [ 70]\n",
            " [ 70]\n",
            " [ 69]\n",
            " [ 32]\n",
            " [ 79]\n",
            " [ 53]\n",
            " [ 59]\n",
            " [ 83]\n",
            " [100]\n",
            " [ 80]\n",
            " [ 80]\n",
            " [ 82]\n",
            " [ 56]\n",
            " [ 83]\n",
            " [ 85]\n",
            " [ 88]\n",
            " [ 81]\n",
            " [ 95]\n",
            " [ 63]\n",
            " [ 70]\n",
            " [ 89]\n",
            " [ 59]\n",
            " [ 56]\n",
            " [ 62]\n",
            " [ 95]\n",
            " [ 63]\n",
            " [ 82]\n",
            " [ 69]\n",
            " [ 58]\n",
            " [ 74]\n",
            " [ 66]\n",
            " [ 82]\n",
            " [ 94]\n",
            " [ 70]\n",
            " [ 78]\n",
            " [ 63]\n",
            " [ 91]\n",
            " [ 70]\n",
            " [ 62]\n",
            " [ 79]\n",
            " [ 65]\n",
            " [ 74]\n",
            " [ 56]\n",
            " [ 65]\n",
            " [100]\n",
            " [ 70]\n",
            " [ 66]\n",
            " [ 54]\n",
            " [ 72]\n",
            " [ 90]\n",
            " [ 56]\n",
            " [ 65]\n",
            " [ 50]\n",
            " [ 95]\n",
            " [ 38]\n",
            " [ 76]\n",
            " [ 84]\n",
            " [ 76]\n",
            " [ 55]\n",
            " [ 85]\n",
            " [ 70]\n",
            " [ 73]\n",
            " [ 80]\n",
            " [ 83]\n",
            " [ 53]\n",
            " [ 67]\n",
            " [100]\n",
            " [ 67]\n",
            " [ 44]\n",
            " [ 96]\n",
            " [ 48]\n",
            " [ 77]\n",
            " [100]\n",
            " [ 40]\n",
            " [ 91]\n",
            " [ 55]\n",
            " [ 41]\n",
            " [ 25]\n",
            " [ 63]\n",
            " [ 59]\n",
            " [ 63]\n",
            " [ 77]\n",
            " [ 46]\n",
            " [ 49]\n",
            " [ 46]\n",
            " [ 93]\n",
            " [ 39]\n",
            " [ 58]\n",
            " [ 87]\n",
            " [ 57]\n",
            " [ 77]\n",
            " [100]\n",
            " [ 65]\n",
            " [ 34]\n",
            " [ 87]\n",
            " [ 81]\n",
            " [ 63]\n",
            " [ 69]\n",
            " [ 74]\n",
            " [ 70]\n",
            " [ 93]\n",
            " [ 63]\n",
            " [ 81]\n",
            " [ 81]\n",
            " [ 63]\n",
            " [ 87]\n",
            " [ 76]\n",
            " [ 54]\n",
            " [ 89]\n",
            " [ 63]\n",
            " [ 76]\n",
            " [ 79]\n",
            " [ 75]\n",
            " [ 50]\n",
            " [ 36]\n",
            " [ 82]\n",
            " [ 83]\n",
            " [ 85]\n",
            " [ 82]\n",
            " [ 41]\n",
            " [ 82]\n",
            " [ 45]\n",
            " [ 57]\n",
            " [ 88]\n",
            " [ 81]\n",
            " [ 98]\n",
            " [ 61]\n",
            " [ 95]\n",
            " [ 84]\n",
            " [ 71]\n",
            " [ 52]\n",
            " [ 71]\n",
            " [ 90]\n",
            " [ 75]\n",
            " [ 62]\n",
            " [ 63]\n",
            " [ 86]\n",
            " [ 70]\n",
            " [ 77]\n",
            " [ 68]\n",
            " [ 80]\n",
            " [ 67]\n",
            " [ 67]\n",
            " [ 89]\n",
            " [ 60]\n",
            " [ 79]\n",
            " [ 80]\n",
            " [ 78]\n",
            " [ 70]\n",
            " [ 72]\n",
            " [ 43]\n",
            " [ 14]\n",
            " [ 54]\n",
            " [ 92]\n",
            " [ 71]\n",
            " [ 65]\n",
            " [ 58]\n",
            " [ 56]\n",
            " [ 67]\n",
            " [ 64]\n",
            " [ 81]\n",
            " [ 55]\n",
            " [ 45]\n",
            " [ 86]\n",
            " [ 52]\n",
            " [ 75]\n",
            " [ 81]\n",
            " [ 62]\n",
            " [ 42]\n",
            " [ 21]\n",
            " [ 72]\n",
            " [ 55]\n",
            " [ 66]\n",
            " [ 69]\n",
            " [ 86]\n",
            " [ 67]\n",
            " [ 78]\n",
            " [ 85]\n",
            " [ 66]\n",
            " [ 47]\n",
            " [100]\n",
            " [ 63]\n",
            " [ 62]\n",
            " [ 61]\n",
            " [ 69]\n",
            " [ 57]\n",
            " [ 76]\n",
            " [ 52]\n",
            " [ 47]\n",
            " [ 51]\n",
            " [ 61]\n",
            " [ 45]\n",
            " [ 59]\n",
            " [ 81]\n",
            " [ 65]\n",
            " [ 53]\n",
            " [ 61]\n",
            " [ 90]\n",
            " [ 74]\n",
            " [ 62]\n",
            " [ 67]\n",
            " [ 50]\n",
            " [ 84]\n",
            " [ 70]\n",
            " [ 52]\n",
            " [ 92]\n",
            " [ 65]\n",
            " [ 65]\n",
            " [ 67]\n",
            " [ 72]\n",
            " [ 66]\n",
            " [ 62]\n",
            " [ 99]\n",
            " [ 62]\n",
            " [ 53]\n",
            " [ 57]\n",
            " [ 78]\n",
            " [ 56]\n",
            " [ 87]\n",
            " [ 79]\n",
            " [ 63]\n",
            " [ 87]\n",
            " [ 86]\n",
            " [ 75]\n",
            " [ 70]\n",
            " [ 60]\n",
            " [ 49]\n",
            " [ 41]\n",
            " [ 78]\n",
            " [ 58]\n",
            " [ 75]\n",
            " [ 89]\n",
            " [ 34]\n",
            " [ 60]\n",
            " [ 80]\n",
            " [ 85]\n",
            " [ 73]\n",
            " [ 58]\n",
            " [ 69]\n",
            " [ 74]\n",
            " [ 52]\n",
            " [ 58]\n",
            " [ 79]\n",
            " [ 86]\n",
            " [ 61]\n",
            " [ 68]\n",
            " [ 67]\n",
            " [ 48]\n",
            " [ 65]\n",
            " [ 73]\n",
            " [ 57]\n",
            " [ 73]\n",
            " [ 57]\n",
            " [ 80]\n",
            " [ 85]\n",
            " [ 81]\n",
            " [ 61]\n",
            " [ 69]\n",
            " [100]\n",
            " [ 99]\n",
            " [ 92]\n",
            " [ 72]\n",
            " [ 57]\n",
            " [ 44]\n",
            " [ 59]\n",
            " [ 62]\n",
            " [ 93]\n",
            " [ 64]\n",
            " [ 57]\n",
            " [ 72]\n",
            " [ 40]\n",
            " [ 85]\n",
            " [ 60]\n",
            " [ 83]\n",
            " [ 63]\n",
            " [ 74]\n",
            " [ 44]\n",
            " [ 61]\n",
            " [ 74]\n",
            " [ 68]\n",
            " [ 78]\n",
            " [ 50]\n",
            " [ 70]\n",
            " [ 68]\n",
            " [ 82]\n",
            " [ 46]\n",
            " [ 96]\n",
            " [100]\n",
            " [ 44]\n",
            " [ 41]\n",
            " [ 95]\n",
            " [ 79]\n",
            " [ 67]\n",
            " [ 52]\n",
            " [ 87]\n",
            " [ 75]\n",
            " [ 61]\n",
            " [ 42]\n",
            " [ 60]\n",
            " [ 57]\n",
            " [ 64]\n",
            " [ 52]\n",
            " [ 68]\n",
            " [ 58]\n",
            " [ 93]\n",
            " [ 75]\n",
            " [ 77]\n",
            " [ 66]\n",
            " [ 63]\n",
            " [ 90]\n",
            " [ 43]\n",
            " [ 65]\n",
            " [ 95]\n",
            " [ 86]\n",
            " [ 31]\n",
            " [ 95]\n",
            " [ 52]\n",
            " [ 63]\n",
            " [ 87]\n",
            " [ 70]\n",
            " [ 59]\n",
            " [ 84]\n",
            " [ 79]\n",
            " [ 77]\n",
            " [ 75]\n",
            " [ 66]\n",
            " [ 69]\n",
            " [ 85]\n",
            " [ 63]\n",
            " [ 50]\n",
            " [ 58]\n",
            " [ 80]\n",
            " [ 47]\n",
            " [ 55]\n",
            " [ 61]\n",
            " [ 87]\n",
            " [ 77]\n",
            " [ 54]\n",
            " [ 66]\n",
            " [ 68]\n",
            " [ 54]\n",
            " [ 69]\n",
            " [ 74]\n",
            " [ 81]\n",
            " [ 72]\n",
            " [ 61]\n",
            " [ 76]\n",
            " [ 63]\n",
            " [ 64]\n",
            " [ 73]\n",
            " [ 62]\n",
            " [ 92]\n",
            " [ 69]\n",
            " [ 70]\n",
            " [ 65]\n",
            " [ 53]\n",
            " [ 74]\n",
            " [ 61]\n",
            " [ 80]\n",
            " [ 85]\n",
            " [ 62]\n",
            " [ 80]\n",
            " [ 83]\n",
            " [ 56]\n",
            " [ 76]\n",
            " [ 52]\n",
            " [ 51]\n",
            " [ 74]\n",
            " [ 57]\n",
            " [ 63]\n",
            " [ 61]\n",
            " [ 87]\n",
            " [ 60]\n",
            " [ 54]\n",
            " [ 89]\n",
            " [ 67]\n",
            " [ 56]\n",
            " [ 70]\n",
            " [ 90]\n",
            " [ 94]\n",
            " [ 78]\n",
            " [ 72]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To - Do - 3:\n",
        "1. Split the dataset into training and test sets.\n",
        "2. You can use an 80-20 or 70-30 split, with 80% (or 70%) of the data used for training and the rest\n",
        "for testing."
      ],
      "metadata": {
        "id": "ChoORTycP5pC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Concept and technologies of AI/student.csv')\n",
        "\n",
        "# Step 1: Split the data into features (X) and label (Y)\n",
        "X = data[['Math', 'Reading']].values\n",
        "Y = data['Writing'].values\n",
        "\n",
        "# Step 2: Split the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Reshape the target vectors into column vectors (for consistency)\n",
        "Y_train = Y_train.reshape(-1, 1)\n",
        "Y_test = Y_test.reshape(-1, 1)\n",
        "\n",
        "# Step 4: Print the shape of the resulting datasets to verify the split\n",
        "print(\"Training set (X_train) shape:\", X_train.shape)\n",
        "print(\"Test set (X_test) shape:\", X_test.shape)\n",
        "print(\"Training labels (Y_train) shape:\", Y_train.shape)\n",
        "print(\"Test labels (Y_test) shape:\", Y_test.shape)\n"
      ],
      "metadata": {
        "id": "y9YWTBe_P7FO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45751039-25a3-42fa-f4a6-e9436ea08300"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set (X_train) shape: (800, 2)\n",
            "Test set (X_test) shape: (200, 2)\n",
            "Training labels (Y_train) shape: (800, 1)\n",
            "Test labels (Y_test) shape: (200, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5nawyFTfQQbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Step 1: Load the data and split it into training and test sets\n",
        "data = pd.read_csv('/content/drive/MyDrive/Concept and technologies of AI/student.csv')\n",
        "X = data[['Math', 'Reading']].values  # Feature matrix\n",
        "Y = data['Writing'].values.reshape(-1, 1)  # Target vector (reshaped into a column vector)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Prepare the feature matrix (X) and target vector (Y)\n",
        "X_train = X_train / np.max(X_train, axis=0)\n",
        "X_test = X_test / np.max(X_test, axis=0)\n",
        "\n",
        "# Step 3: Define the weight matrix (W) and initialize learning rate and number of iterations\n",
        "W = np.random.randn(X_train.shape[1], 1)\n",
        "alpha = 0.01\n",
        "iterations = 1000\n",
        "\n",
        "# Gradient Descent Function\n",
        "def gradient_descent(X, Y, W, alpha, iterations):\n",
        "    m = len(Y)\n",
        "    for i in range(iterations):\n",
        "        # Calculate predictions\n",
        "        Y_pred = np.dot(X, W)\n",
        "        # Compute loss\n",
        "        loss = Y_pred - Y\n",
        "        # Compute gradient\n",
        "        dW = (1 / m) * np.dot(X.T, loss)\n",
        "        # Update weights\n",
        "        W = W - alpha * dW\n",
        "        # Optional: Print loss every 100 iterations\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Iteration {i}, Loss: {np.mean(loss**2)}\")\n",
        "\n",
        "    return W\n",
        "\n",
        "# Step 4: Call the gradient descent function to learn the parameters\n",
        "W_optimized = gradient_descent(X_train, Y_train, W, alpha, iterations)\n",
        "\n",
        "# Step 5: Evaluate the model using RMSE and R^2\n",
        "Y_test_pred = np.dot(X_test, W_optimized)\n",
        "\n",
        "# Compute RMSE\n",
        "rmse = np.sqrt(mean_squared_error(Y_test, Y_test_pred))\n",
        "\n",
        "# Compute R^2 Score\n",
        "r2 = r2_score(Y_test, Y_test_pred)\n",
        "\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "print(\"R-squared (R2):\", r2)"
      ],
      "metadata": {
        "id": "C7xs7EgKnMv4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f932305e-adb8-46f3-ee76-9d04aad7d0a9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Loss: 5024.0129099303795\n",
            "Iteration 100, Loss: 727.5779618747752\n",
            "Iteration 200, Loss: 130.83410323876143\n",
            "Iteration 300, Loss: 47.86127605443866\n",
            "Iteration 400, Loss: 36.23589446107741\n",
            "Iteration 500, Loss: 34.519301272678234\n",
            "Iteration 600, Loss: 34.17960171667618\n",
            "Iteration 700, Loss: 34.031977819819296\n",
            "Iteration 800, Loss: 33.9118883742962\n",
            "Iteration 900, Loss: 33.79647642440609\n",
            "Root Mean Squared Error (RMSE): 5.906620021372308\n",
            "R-squared (R2): 0.8606245894645321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To-Do:\n",
        " 1. Loads the data and splits it into training and test sets."
      ],
      "metadata": {
        "id": "g9ucAtLi31Qk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Concept and technologies of AI/student.csv')\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtoJsaLj4dlF",
        "outputId": "7a548b41-e8a5-4e39-89ee-3f5a98fefaea"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Math  Reading  Writing\n",
            "0    48       68       63\n",
            "1    62       81       72\n",
            "2    79       80       78\n",
            "3    76       83       79\n",
            "4    59       64       62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 2. Prepares the feature matrix(X) and target vector(Y)."
      ],
      "metadata": {
        "id": "ftEPpEHQ5MAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[['Math', 'Reading']].values  # Feature matrix\n",
        "Y = data['Writing'].values.reshape(-1, 1)\n",
        "\n",
        "# Step 2: Optionally, normalize or scale the features for better gradient descent performance\n",
        "X = X / np.max(X, axis=0)\n",
        "\n",
        "# Step 3: Print shapes to verify\n",
        "print(\"Feature matrix (X) shape:\", X.shape)\n",
        "print(\"Target vector (Y) shape:\", Y.shape)\n",
        "\n",
        "# Step 4: Optional: Display a few rows of the prepared feature matrix and target vector\n",
        "print(\"Sample features (X):\", X[:5])\n",
        "print(\"Sample target (Y):\", Y[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdW_WU0q5qen",
        "outputId": "1301996c-5d1f-4cc9-dc1f-43d52794a446"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature matrix (X) shape: (1000, 2)\n",
            "Target vector (Y) shape: (1000, 1)\n",
            "Sample features (X): [[0.48 0.68]\n",
            " [0.62 0.81]\n",
            " [0.79 0.8 ]\n",
            " [0.76 0.83]\n",
            " [0.59 0.64]]\n",
            "Sample target (Y): [[63]\n",
            " [72]\n",
            " [78]\n",
            " [79]\n",
            " [62]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines the weight matrix(W)and initializes the learning rate and number of iterations."
      ],
      "metadata": {
        "id": "uoM-tjsz50XW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define the weight matrix (W)\n",
        "W = np.random.randn(2, 1)  # For 2 features: 'Math' and 'Reading'\n",
        "\n",
        "# Step 2: Initialize the learning rate (alpha)\n",
        "alpha = 0.01  # Small positive value to control the step size during updates\n",
        "\n",
        "# Step 3: Set the number of iterations\n",
        "iterations = 1000\n",
        "\n",
        "# Display the initialized parameters\n",
        "print(\"Initial weight matrix (W):\", W)\n",
        "print(\"Learning rate (alpha):\", alpha)\n",
        "print(\"Number of iterations:\", iterations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cV7FwhEV572b",
        "outputId": "f2d8a1f3-4e3e-4200-826a-d92a47a947c9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial weight matrix (W): [[-0.71952667]\n",
            " [-0.11861612]]\n",
            "Learning rate (alpha): 0.01\n",
            "Number of iterations: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Evaluates the model using RMSE and R2"
      ],
      "metadata": {
        "id": "nFpdEAdR6ULC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Predict values for the test set\n",
        "Y_test_pred = np.dot(X_test, W_optimized)\n",
        "\n",
        "# Step 2: Compute RMSE\n",
        "rmse = np.sqrt(mean_squared_error(Y_test, Y_test_pred))\n",
        "\n",
        "# Step 3: Compute R²\n",
        "r2 = r2_score(Y_test, Y_test_pred)\n",
        "\n",
        "# Step 4: Print the evaluation metrics\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "print(\"R-squared (R²):\", r2)\n"
      ],
      "metadata": {
        "id": "LQ-Lw1H66TyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b88a6ad8-67fb-4cbb-9b21-abc8732220f3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 5.906620021372308\n",
            "R-squared (R²): 0.8606245894645321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Present your finding:\n",
        " 1. Did your Model Overfitt, Underfitts, or performance is acceptable.\n",
        " 2. Experiment with different value of learning rate, making it higher and lower, observe the result."
      ],
      "metadata": {
        "id": "O9J2vYB36uZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [0.001, 0.01, 0.1, 0.5]\n",
        "\n",
        "for lr in learning_rates:\n",
        "    print(f\"\\nExperimenting with learning rate: {lr}\")\n",
        "    W = np.random.randn(X_train.shape[1], 1)\n",
        "    W_optimized = gradient_descent(X_train, Y_train, W, alpha=lr, iterations=1000)\n",
        "\n",
        "    # Predict and evaluate\n",
        "    Y_test_pred = np.dot(X_test, W_optimized)\n",
        "    rmse = np.sqrt(mean_squared_error(Y_test, Y_test_pred))\n",
        "    r2 = r2_score(Y_test, Y_test_pred)\n",
        "\n",
        "    print(f\"Learning Rate: {lr}\")\n",
        "    print(f\"RMSE: {rmse}\")\n",
        "    print(f\"R-squared (R^2): {r2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeV7Dy466xI1",
        "outputId": "605bc9e7-c07a-4a16-8ec4-e10955a2406d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Experimenting with learning rate: 0.001\n",
            "Iteration 0, Loss: 5094.265396737515\n",
            "Iteration 100, Loss: 4191.337015747409\n",
            "Iteration 200, Loss: 3449.523538679681\n",
            "Iteration 300, Loss: 2840.0759007502147\n",
            "Iteration 400, Loss: 2339.374970887871\n",
            "Iteration 500, Loss: 1928.0161751785856\n",
            "Iteration 600, Loss: 1590.0574585290292\n",
            "Iteration 700, Loss: 1312.4014387585987\n",
            "Iteration 800, Loss: 1084.2878080534801\n",
            "Iteration 900, Loss: 896.8763094329194\n",
            "Learning Rate: 0.001\n",
            "RMSE: 27.310844607304436\n",
            "R-squared (R^2): -1.9797398954063197\n",
            "\n",
            "Experimenting with learning rate: 0.01\n",
            "Iteration 0, Loss: 5037.402092874841\n",
            "Iteration 100, Loss: 728.8083811396095\n",
            "Iteration 200, Loss: 130.38144663153568\n",
            "Iteration 300, Loss: 47.18023921039266\n",
            "Iteration 400, Loss: 35.528442783674016\n",
            "Iteration 500, Loss: 33.81343593224549\n",
            "Iteration 600, Loss: 33.47916614074408\n",
            "Iteration 700, Loss: 33.3374610753885\n",
            "Iteration 800, Loss: 33.22331409665739\n",
            "Iteration 900, Loss: 33.113803994741005\n",
            "Learning Rate: 0.01\n",
            "RMSE: 5.851328784625326\n",
            "R-squared (R^2): 0.8632217330611\n",
            "\n",
            "Experimenting with learning rate: 0.1\n",
            "Iteration 0, Loss: 4908.1619868866\n",
            "Iteration 100, Loss: 33.14216446426801\n",
            "Iteration 200, Loss: 32.10053578888849\n",
            "Iteration 300, Loss: 31.144864266857212\n",
            "Iteration 400, Loss: 30.26805226087173\n",
            "Iteration 500, Loss: 29.463592489792454\n",
            "Iteration 600, Loss: 28.72551463631054\n",
            "Iteration 700, Loss: 28.04834103809617\n",
            "Iteration 800, Loss: 27.427046035197336\n",
            "Iteration 900, Loss: 26.85701867198516\n",
            "Learning Rate: 0.1\n",
            "RMSE: 5.282718155958012\n",
            "R-squared (R^2): 0.8885133219985929\n",
            "\n",
            "Experimenting with learning rate: 0.5\n",
            "Iteration 0, Loss: 4935.137235540544\n",
            "Iteration 100, Loss: 29.383776198942833\n",
            "Iteration 200, Loss: 26.279999244359168\n",
            "Iteration 300, Loss: 24.26294092615034\n",
            "Iteration 400, Loss: 22.95211082508683\n",
            "Iteration 500, Loss: 22.100238800196653\n",
            "Iteration 600, Loss: 21.5466308641249\n",
            "Iteration 700, Loss: 21.186856463831454\n",
            "Iteration 800, Loss: 20.953049087396494\n",
            "Iteration 900, Loss: 20.801104176277722\n",
            "Learning Rate: 0.5\n",
            "RMSE: 4.795371240950314\n",
            "R-squared (R^2): 0.9081344748476503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "1. Very Low Learning Rate\n",
        "\n",
        "\n",
        "*   Model converges very slowly.\n",
        "*   Loss decreases at a sluggish pace, requiring more iterations for acceptable performance.\n",
        "\n",
        "2. Optimal Learning Rate\n",
        "\n",
        "*   Achieves convergence in a reasonable number of iterations.\n",
        "*   Produces good RMSE and 𝑅2 scores.\n",
        "\n",
        "3. High learning rate\n",
        "\n",
        "\n",
        "*   Loss might oscillate or even diverge.\n",
        "*   RMSE increases, and 𝑅2 may decrease due to instability.\n"
      ],
      "metadata": {
        "id": "6uHb48FZ63uv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a Cost Function:"
      ],
      "metadata": {
        "id": "h94EgPiYAJw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the cost function\n",
        "def cost_function(X, Y, W):\n",
        "    \"\"\" Parameters:\n",
        "    This function finds the Mean Square Error.\n",
        "    Input parameters:\n",
        "    X: Feature Matrix\n",
        "    Y: Target Matrix\n",
        "    W: Weight Matrix\n",
        "    Output Parameters:\n",
        "    cost: accumulated mean square error.\n",
        "    \"\"\"\n",
        "    # Calculate predictions\n",
        "    Y_pred = np.dot(X, W)\n",
        "\n",
        "    # Calculate the difference between predictions and actual values\n",
        "    error = Y_pred - Y\n",
        "\n",
        "    # Calculate the squared error\n",
        "    squared_error = error**2\n",
        "\n",
        "    # Calculate the mean squared error\n",
        "    cost = np.mean(squared_error)\n",
        "\n",
        "    return cost # Return the calculated cost"
      ],
      "metadata": {
        "id": "w-mxp99wAKhN"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Designing a Test Case for Cost Function:"
      ],
      "metadata": {
        "id": "bdM56bTEAWJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "Y_test = np.array([3, 7, 11])\n",
        "W_test = np.array([1, 1])\n",
        "cost = cost_function(X_test, Y_test, W_test)\n",
        "if cost == 0:\n",
        "    X_test = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "    Y_test = np.array([3, 7, 11])\n",
        "    W_test = np.array([1, 1])\n",
        "    cost = cost_function(X_test, Y_test, W_test)\n",
        "    if cost == 0:\n",
        "        print(\"Proceed Further\")\n",
        "else:\n",
        "    print(\"something went wrong: Reimplement\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbXGJl9QAZer",
        "outputId": "fa278228-5cf6-475c-dc9a-8dfb43063c72"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proceed Further\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Descent Update Rule"
      ],
      "metadata": {
        "id": "P-qAKF8MAiLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, Y, W, alpha, iterations):\n",
        "    \"\"\"\n",
        "    Perform gradient descent to optimize the parameters of a linear regression model.\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Feature matrix (m x n).\n",
        "    Y (numpy.ndarray): Target vector (m x 1).\n",
        "    W (numpy.ndarray): Initial guess for parameters (n x 1).\n",
        "    alpha (float): Learning rate.\n",
        "    iterations (int): Number of iterations for gradient descent.\n",
        "    Returns:\n",
        "    tuple: A tuple containing the final optimized parameters (W_update) and the history of cost values\n",
        "    .\n",
        "    W_update (numpy.ndarray): Updated parameters (n x 1).\n",
        "    cost_history (list): History of cost values over iterations.\n",
        "    \"\"\"\n",
        "    # Initialize cost history\n",
        "    cost_history = [0] * iterations\n",
        "    # Number of samples\n",
        "    m = len(Y)\n",
        "    for iteration in range(iterations):\n",
        "        # Step 1: Hypothesis Values\n",
        "        Y_pred = np.dot(X, W)  # Prediction using current weights\n",
        "        # Step 2: Difference between Hypothesis and Actual Y\n",
        "        loss = Y_pred - Y     # Error calculation\n",
        "        # Step 3: Gradient Calculation\n",
        "        dw = (1/m) * np.dot(X.T, loss)  # Gradient of the cost function\n",
        "        # Step 4: Updating Values of W using Gradient\n",
        "        W_update = W - alpha * dw    # Weight update using gradient descent\n",
        "        # Step 5: New Cost Value\n",
        "        cost = cost_function(X, Y, W_update)\n",
        "        cost_history[iteration] = cost\n",
        "    return W_update, cost_history # Return updated weights and cost history\n",
        "\n"
      ],
      "metadata": {
        "id": "DCytQAKCA2wV"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Code for Gradient Descent function:"
      ],
      "metadata": {
        "id": "OvUu8ZWrBFt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate random test data\n",
        "np.random.seed(0) # For reproducibility\n",
        "X = np.random.rand(100, 3) # 100 samples, 3 features\n",
        "Y = np.random.rand(100)\n",
        "W = np.random.rand(3) # Initial guess for parameters\n",
        "# Set hyperparameters\n",
        "alpha = 0.01\n",
        "iterations = 1000\n",
        "# Test the gradient_descent function\n",
        "final_params, cost_history = gradient_descent(X, Y, W, alpha, iterations)\n",
        "# Print the final parameters and cost history\n",
        "print(\"Final Parameters:\", final_params)\n",
        "print(\"Cost History:\", cost_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn2DzLG6BL87",
        "outputId": "c28ccc3a-2f9a-4a12-a726-badb7d30defb"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Parameters: [0.3996496  0.92745322 0.09826523]\n",
            "Cost History: [0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307, 0.21422394189320307]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Root Mean Square Error:"
      ],
      "metadata": {
        "id": "vH8G_QaTBPjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation - RMSE\n",
        "def rmse(Y, Y_pred):\n",
        "    \"\"\"\n",
        "    This Function calculates the Root Mean Squres.\n",
        "    Input Arguments:\n",
        "    Y: Array of actual(Target) Dependent Varaibles.\n",
        "    Y_pred: Array of predeicted Dependent Varaibles.\n",
        "    Output Arguments:\n",
        "    rmse: Root Mean Square.\n",
        "    \"\"\"\n",
        "    rmse = np.sqrt(np.mean((Y - Y_pred)**2)) # Calculate RMSE\n",
        "    return rmse # Return the calculated RMSE"
      ],
      "metadata": {
        "id": "Lg_uGKO-BSmI"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for R-Squared Error:"
      ],
      "metadata": {
        "id": "YTx1rn6LBcqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation - R2\n",
        "def r2(Y, Y_pred):\n",
        "    \"\"\"\n",
        "    This Function calculates the R Squared Error.\n",
        "    Input Arguments:\n",
        "    Y: Array of actual(Target) Dependent Varaibles.\n",
        "    Y_pred: Array of predeicted Dependent Varaibles.\n",
        "    Output Arguments:\n",
        "    rsquared: R Squared Error.\n",
        "    \"\"\"\n",
        "    mean_y = np.mean(Y)\n",
        "    ss_tot = np.sum((Y - mean_y)**2) # Calculate total sum of squares\n",
        "    ss_res = np.sum((Y - Y_pred)**2) # Calculate residual sum of squares\n",
        "    r2 = 1 - (ss_res / ss_tot)     # Calculate R-squared\n",
        "    return r2 # Return the calculated R-squared"
      ],
      "metadata": {
        "id": "i877NcK4Bfw4"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Function to Integrate All Steps:"
      ],
      "metadata": {
        "id": "B5UPHCKpBqj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Step 1: Load the dataset\n",
        "    data = pd.read_csv('/content/drive/MyDrive/Concept and technologies of AI/student.csv')\n",
        "    # Step 2: Split the data into features (X) and target (Y)\n",
        "    X = data[['Math', 'Reading']].values # Features: Math and Reading marks\n",
        "    Y = data['Writing'].values # Target: Writing marks\n",
        "    # Step 3: Split the data into training and test sets (80% train, 20% test)\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "    # Step 4: Initialize weights (W) to zeros, learning rate and number of iterations\n",
        "    W = np.zeros(X_train.shape[1]) # Initialize weights\n",
        "    alpha = 0.00001 # Learning rate\n",
        "    iterations = 1000 # Number of iterations for gradient descent\n",
        "    # Step 5: Perform Gradient Descent\n",
        "    W_optimal, cost_history = gradient_descent(X_train, Y_train, W, alpha, iterations)\n",
        "    # Step 6: Make predictions on the test set\n",
        "    Y_pred = np.dot(X_test, W_optimal)\n",
        "    # Step 7: Evaluate the model using RMSE and R-Squared\n",
        "    model_rmse = rmse(Y_test, Y_pred)\n",
        "    model_r2 = r2(Y_test, Y_pred)\n",
        "    # Step 8: Output the results\n",
        "    print(\"Final Weights:\", W_optimal)\n",
        "    print(\"Cost History (First 10 iterations):\", cost_history[:10])\n",
        "    print(\"RMSE on Test Set:\", model_rmse)\n",
        "    print(\"R-Squared on Test Set:\", model_r2)\n",
        "# Execute the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAhzMVP4BrQS",
        "outputId": "334d1de1-7ec3-43a3-ea37-00a13e2e3f23"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Weights: [0.04797833 0.05020199]\n",
            "Cost History (First 10 iterations): [4026.33114156751, 4026.33114156751, 4026.33114156751, 4026.33114156751, 4026.33114156751, 4026.33114156751, 4026.33114156751, 4026.33114156751, 4026.33114156751, 4026.33114156751]\n",
            "RMSE on Test Set: 63.36563528655014\n",
            "R-Squared on Test Set: -15.04041794561271\n"
          ]
        }
      ]
    }
  ]
}